{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42eb9b8a-896d-46ae-bb94-15a0fc1d67e9",
   "metadata": {},
   "source": [
    "# Engram\n",
    "\n",
    "git: [dhcode-cpp/Engram-pytorch](https://github.com/dhcode-cpp/Engram-pytorch)\n",
    "\n",
    "Blog: [【手撕Engram】DeepSeek 的 Conditional Memory 能取代 Attention 吗？](https://zhuanlan.zhihu.com/p/1994713080131772751)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8b01d7-9228-4047-87f9-acf5d478f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass, field\n",
    "import math\n",
    "\n",
    "## third-class\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c037b30-9709-46a1-8df7-3a8e53d8e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EngramModelConfig:\n",
    "    dim: int = 512\n",
    "    head_dim: int = 64\n",
    "    max_n_gram: int = 3\n",
    "    max_memory_vocab_size: int = 1007\n",
    "    head_hash: int = 8\n",
    "    n_hc: int = 4 # ignore\n",
    "    num_layer: int = 4\n",
    "    vocab_size: int = 100\n",
    "    kernel_size: int = 4 # 序列卷积核\n",
    "\n",
    "config = EngramModelConfig()\n",
    "\n",
    "bsz = 2\n",
    "seq_len = 100\n",
    "\n",
    "x = torch.randint(config.vocab_size, \n",
    "                  size=(bsz, seq_len))\n",
    "\n",
    "H = torch.randn(bsz, seq_len, config.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625878a-d594-4973-a36b-f0a4ef555be8",
   "metadata": {},
   "source": [
    "# Engram Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccb6786-29bd-48d5-bb29-9afb4488e015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "class EngramSimple(nn.Module):\n",
    "    def __init__(self, \n",
    "                 memory_vocab_size, \n",
    "                 dim, \n",
    "                 kernel_size=2):\n",
    "        super().__init__()\n",
    "        self.memory_vocab_size = memory_vocab_size\n",
    "        self.memory_embd = nn.Embedding(memory_vocab_size, dim)\n",
    "        self.Wk = nn.Linear(dim, dim)\n",
    "        self.Wv = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.w_conv1d = nn.Parameter(torch.randn(kernel_size))\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        \"\"\"\n",
    "            h: bsz, seq_len, dim\n",
    "            x: bsz, seq_len\n",
    "        \"\"\"\n",
    "        B, T, D = h.shape\n",
    "\n",
    "        # 1. Multi-heads-hash memory\n",
    "        hash_id = self.multi_head_hash(x)\n",
    "        h_memory = self.get_memory(hash_id) # B, T, D\n",
    "\n",
    "        # 2. Scale-Dot-Product Fusion\n",
    "        q, k, v = h, self.Wk(h_memory), self.Wv(h_memory)\n",
    "        gate = (q * k).sum(dim=2, keepdim=True)\n",
    "        v_ = gate * v # B, T, D\n",
    "\n",
    "        # 3. short-conv1d\n",
    "        out = self.short_conv1d(v_)\n",
    "        return out\n",
    "\n",
    "    def multi_head_hash(self, x):\n",
    "        B, T = x.shape\n",
    "        hash_id = torch.randint(self.memory_vocab_size, (B,T)) # 随机hash\n",
    "        return hash_id\n",
    "\n",
    "    def get_memory(self, hash_id):\n",
    "        h_memory = self.memory_embd(hash_id)\n",
    "        return h_memory\n",
    "\n",
    "    def short_conv1d(self, v):\n",
    "        \"\"\"简化conv1d, 相邻时刻相加\"\"\"\n",
    "        v0 = v * self.w_conv1d[0]\n",
    "        v1 = v * self.w_conv1d[1]\n",
    "        v0[:, :, 1:] += v1[:,:,:-1]\n",
    "        return v0\n",
    "\n",
    "model = EngramSimple(memory_vocab_size=1000, \n",
    "                 dim=128, \n",
    "                 kernel_size=2,)\n",
    "x = torch.randint(12948, (1,10))\n",
    "h = torch.randn(1, 10, 128)\n",
    "y=model(x,h)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62693888-da61-4caf-8459-f65b8a0ac54b",
   "metadata": {},
   "source": [
    "## hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dbb003-fe62-45c2-9bf9-c28448a2b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadsHash:\n",
    "    def __init__(self, max_memory_vocab_size, layer_id):\n",
    "        \n",
    "        self.mods = torch.tensor([12582917, 25165843, 50331653, 100663319, 201326611, 402653189, 805306457, 1610612741]) # 素数\n",
    "        self.mods *= (layer_id+1) # 每层哈希结果不同\n",
    "        self.max_memory_vocab_size = max_memory_vocab_size\n",
    "        self.layer_id = layer_id\n",
    "\n",
    "    def hash(self, x, mod, n_gram):\n",
    "        x_ = x.clone()\n",
    "        for i in range(1, n_gram):\n",
    "            x_[:, i:] *= x[:, :-i]\n",
    "        hash_id = x_ % mod \n",
    "        hash_id = hash_id % self.max_memory_vocab_size\n",
    "        return hash_id\n",
    "\n",
    "    def multi_head_hash(self, x, mods, n_gram):\n",
    "        hash_ids = []\n",
    "        for mod in mods:\n",
    "            hash_id = self.hash(x, mod, n_gram)\n",
    "            hash_ids.append(hash_id)\n",
    "        hash_ids = torch.stack(hash_ids, dim=-1) # bsz, seq_len, hash_head\n",
    "        return hash_ids\n",
    "\n",
    "    def get_all_hash_ids(self, x, max_n_gram):\n",
    "        ngram_hash_ids = []\n",
    "        for N in range(1, max_n_gram):\n",
    "            hash_ids = self.multi_head_hash(x, self.mods, N)\n",
    "            ngram_hash_ids.append(hash_ids)\n",
    "        return ngram_hash_ids # [ [bsz, seq_len, hash_head], [bsz, seq_len, hash_head] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6118da43-8a64-4d34-9e04-e115218be174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 8])\n",
      "torch.Size([1, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "mhash = MultiHeadsHash(config.max_memory_vocab_size, layer_id = 3)\n",
    "hash_ids = mhash.get_all_hash_ids(x, config.max_n_gram)\n",
    "\n",
    "print(x.shape)\n",
    "print(hash_ids[0].shape) # 2-gram, 8-hash-head\n",
    "print(hash_ids[1].shape) # 3-gram, 8-hash-head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf19616-0dd7-4b77-814c-22677345644c",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8849c12-7095-4b75-8a0a-8da078d31aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalMemory(nn.Module):\n",
    "    def __init__(self,  \n",
    "                 config\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_dim = config.head_dim\n",
    "        max_memory_vocab_size=config.max_memory_vocab_size\n",
    "        self.head_hash = config.head_hash\n",
    "\n",
    "        # self.memory_embds = [ nn.Embedding(max_memory_vocab_size, head_dim) for i in range(head_hash) ]\n",
    "        self.memory_embds = nn.Embedding(max_memory_vocab_size * self.head_hash, self.head_dim)\n",
    "        self.offset = torch.arange(self.head_hash) * max_memory_vocab_size \n",
    "        self.offset = self.offset[None, None, 1]\n",
    "\n",
    "    def forward(self, x, ngram_hash_ids):\n",
    "        bsz, seq_len = x.shape\n",
    "        n = len(ngram_hash_ids)\n",
    "        \n",
    "        x += self.offset\n",
    "        ngram_memory = []\n",
    "        for hash_ids in ngram_hash_ids:\n",
    "            memory = self.memory_embds(hash_ids)\n",
    "            ngram_memory.append(memory)\n",
    "        h_memory = torch.cat(ngram_memory, dim = -1)\n",
    "        h_memory = h_memory.reshape(bsz, seq_len, n*self.head_hash*self.head_dim) # 提前 cat\n",
    "        return h_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78d7203-244c-4422-9ae4-72e3e4cee6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1024])\n"
     ]
    }
   ],
   "source": [
    "memory = ConditionalMemory(config)\n",
    "h_memory = memory(x, hash_ids)\n",
    "print(h_memory.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d719c5-cd85-4e21-bf7a-cbc5557228ba",
   "metadata": {},
   "source": [
    "# Engram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1eb466-9118-465b-a450-f76102ead387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngramWithoutHC(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 layer_id=1,\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        D = config.dim\n",
    "        memory_dim = config.head_dim * config.head_hash * (config.max_n_gram-1)\n",
    "        self.max_n_gram = config.max_n_gram\n",
    "\n",
    "        # proj\n",
    "        self.Wk = nn.Linear(memory_dim, D) \n",
    "        self.Wv = nn.Linear(memory_dim, D)\n",
    "        self.norm1 = nn.RMSNorm(D)\n",
    "        self.norm2 = nn.RMSNorm(D)\n",
    "\n",
    "        # op\n",
    "        self.hash = MultiHeadsHash(max_memory_vocab_size=config.max_memory_vocab_size, layer_id=layer_id)\n",
    "        self.memory = ConditionalMemory(config)\n",
    "        # self.conv = ShortConv1D(config.dim, \n",
    "        #                         config.n_hc, \n",
    "        #                         config.kernel_size)\n",
    "\n",
    "    def forward(self, h, x):\n",
    "        \"\"\"\n",
    "            h: bsz, seq_len, dim\n",
    "                hidden states\n",
    "               \n",
    "            x: bsz, seq_len\n",
    "                input ids\n",
    "        \"\"\"\n",
    "        \n",
    "        _, _, D = h.shape\n",
    "        \n",
    "        ngram_hash_id = self.hash.get_all_hash_ids(x, self.max_n_gram)\n",
    "        h_memory = self.memory(x, ngram_hash_id)\n",
    "\n",
    "        # proj\n",
    "        q = self.norm1(h)\n",
    "        k = self.norm2(self.Wk(h_memory))\n",
    "        # score\n",
    "        gate = (q * k).sum(dim=-1, keepdim=True) / math.sqrt(D) # bsz, seq_len, 1\n",
    "        gate = torch.sigmoid(gate)\n",
    "\n",
    "        # value\n",
    "        v_ = gate * self.Wv(h_memory)\n",
    "\n",
    "        # Skip Conv1D \n",
    "        # out = self.conv(v_) + v_\n",
    "        out = v_\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1631d4d6-2eaa-4d2e-ba2a-bbcfd21edf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "engram = EngramWithoutHC(config, layer_id=1)\n",
    "\n",
    "x = torch.randint(config.vocab_size, \n",
    "                  size=(bsz, seq_len))\n",
    "h = torch.randn(bsz, seq_len, config.dim)\n",
    "\n",
    "y = engram(h, x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911ff3e-beb6-4ca1-91d9-d89060201496",
   "metadata": {},
   "source": [
    "# Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddb506-5f2b-4689-8d48-e82a0deec23b",
   "metadata": {},
   "source": [
    "## Conv1D for 1-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f467cf4-2c69-4330-b49d-78ffbc34686a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1, 2, 3, 4] w: [1, 10, 100]\n",
      "[0, 0, 1] * [1, 10, 100] -> 100\n",
      "[0, 1, 2] * [1, 10, 100] -> 210\n",
      "[1, 2, 3] * [1, 10, 100] -> 321\n",
      "[2, 3, 4] * [1, 10, 100] -> 432\n",
      "[100, 210, 321, 432]\n"
     ]
    }
   ],
   "source": [
    "def fun_conv1d(x, w):\n",
    "    kernel_size = len(w)\n",
    "    x_len = len(x)\n",
    "    x_padding = [0] * (kernel_size-1) + x\n",
    "    \n",
    "    x_conv1d = []\n",
    "    for i in range(x_len):\n",
    "        x_tmp = 0\n",
    "        for j in range(kernel_size):\n",
    "            x_tmp += x_padding[i+j] * w[j]\n",
    "        print(x_padding[i: i+kernel_size], '*' ,w, '->', x_tmp)\n",
    "        x_conv1d.append(x_tmp)\n",
    "        \n",
    "    return x_conv1d\n",
    "\n",
    "x = [1, 2, 3, 4]\n",
    "w = [1, 10, 100]\n",
    "\n",
    "\n",
    "print('x:', x, 'w:', w)\n",
    "y = fun_conv1d(x, w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bac34-f40f-4e8a-83bd-46fd90b1ee27",
   "metadata": {},
   "source": [
    "## Conv1D for 1-dimension Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2220b480-997b-43be-9e3f-38a8361a714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4])\n",
      "tensor([100., 210., 321., 432.], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "conv = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=1,\n",
    "            bias=False,\n",
    "            padding=(kernel_size - 1) * 1, # 3\n",
    "            dilation=1,\n",
    "        )\n",
    "x_len = len(x)\n",
    "x_tensor = torch.tensor([x], dtype=torch.float32).unsqueeze(dim = 1)\n",
    "print(x_tensor.shape) # B, C, T\n",
    "conv.weight.data = torch.tensor([[[1,10,100]]],dtype=torch.float32)\n",
    "y = conv(x_tensor)\n",
    "print(y[0,0,:x_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412ccbd-a451-4d3a-b70f-b17fae4b6728",
   "metadata": {},
   "source": [
    "## Conv1D for hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcef9e0d-59dd-4ea7-98e3-c9eff329aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 128])\n",
      "shape_groupC: torch.Size([128, 1, 3])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "B = 1\n",
    "T = 10\n",
    "C = 128 # channel, dim(D)\n",
    "X = torch.randn(B, T, C)\n",
    "print(X.shape)\n",
    "X = X.transpose(1,2) # B, C, T\n",
    "\n",
    "conv_3C = nn.Conv1d(in_channels=C, out_channels=C, kernel_size=kernel_size,\n",
    "            groups=C, padding=(kernel_size - 1) * 1, dilation=1, bias=False,)\n",
    "print('shape_groupC:', conv_3C.weight.data.shape)\n",
    "Y = conv_3C(X)\n",
    "Y = Y.transpose(1,2)[:, :T]\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6ec6b-6305-4ed5-84dc-0c3e1fff1d02",
   "metadata": {},
   "source": [
    "## ShortConv1DWithoutHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5f6e87-64c4-4519-afd4-3f9553791600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortConv1DWithoutHC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 kernel_size,):\n",
    "        super().__init__()\n",
    "        \n",
    "        dilation=1\n",
    "        self.total_dim = dim \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=self.total_dim,\n",
    "            out_channels=self.total_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=self.total_dim,\n",
    "            bias=False,\n",
    "            padding=(kernel_size - 1) * dilation, # 3\n",
    "            dilation=dilation,\n",
    "        )\n",
    "\n",
    "        self.norm = nn.RMSNorm( dim )\n",
    "        self.act_fn = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape \n",
    "\n",
    "        x_norm = self.norm(x)\n",
    "        x_norm = x_norm.transpose(1, 2) # B, C, T\n",
    "        y = self.conv(x_norm)\n",
    "        y = y[..., :T]\n",
    "\n",
    "        y = self.act_fn(y) # swiglu\n",
    "        y = y.transpose(1,2)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef8a4c0-27a0-4725-bfde-44738bfe8e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 1024])\n",
      "torch.Size([2, 10, 1024])\n"
     ]
    }
   ],
   "source": [
    "conv = ShortConv1DWithoutHC(\n",
    "    dim=config.dim * (config.max_n_gram-1), \n",
    "    kernel_size=config.kernel_size,\n",
    ")\n",
    "\n",
    "\n",
    "V_ = torch.randn(2, 10, config.dim*(config.max_n_gram-1))\n",
    "V_conv1d = conv(V_)\n",
    "\n",
    "print(V_.shape)\n",
    "print(V_conv1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37074ec7-2ef3-42b6-86f4-672cbb7b6129",
   "metadata": {},
   "source": [
    "## Engram With Hyper Connection\n",
    "\n",
    "Read `./Engram.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
