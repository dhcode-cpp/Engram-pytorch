# Engram

git: [dhcode-cpp/Engram-pytorch](https://github.com/dhcode-cpp/Engram-pytorch)

Blog: [【手撕Engram】DeepSeek 的 Conditional Memory 能取代 Attention 吗？](https://zhuanlan.zhihu.com/p/1994713080131772751)

# Run

Use multi-mods-hash function instead of Multiplicative-XOR hash funciton.

1. `Engram-without-Hyper-Connection.ipynb`
2. `Engram.ipynb`

# Reference: 

Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models